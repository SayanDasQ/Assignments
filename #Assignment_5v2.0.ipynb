{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5v2.0\n",
    "\n",
    "# Implementing CNN using TensorFlow and improving the architecture using Batch normalization and Dropout techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents :\n",
    "\n",
    "* Data extraction\n",
    "* Visualizing the data\n",
    "* Defining Data Augumentation functions\n",
    "* Data engineeering (one hot encoding)\n",
    "* Applying Image transformations\n",
    "* Defining functons for Convolution, Max pool, ReLU, Flatten, Batch Normalization, Dropout and Fully connected layers.\n",
    "* Setting the sequence of the execution of Layers\n",
    "* Running the session\n",
    "* The hyperparameters :\n",
    "    * Number of Epochs: 100\n",
    "    * Batch size: 100\n",
    "    * Number of augumented batches: 6\n",
    "    * Learning rate: alpha = 1e-3\n",
    "    * Convolution layers: 3, filter size = 5*5, strides = [1,1,1,1] \n",
    "    * Max pool layers: 3, filter size = 2*2, strides = [1,2,2,1]\n",
    "    * ReLU layers: 3\n",
    "    * Fully connected layers: 2\n",
    "    * Batch normalization layers: 3\n",
    "    * Dropout layers: 1\n",
    "    * Flatten layer: 1\n",
    "* The layer sequence of the architecture: conv1 > pool1 > bat_norm1 > relu1 > dout1 > conv2 > pool2 > bat_norm2 > relu2 > dout2 > flatten > fc1 > bat_norm3 > relu3 > dout3 > fc2\n",
    "* In 10 epochs:\n",
    "        * Training accuracy = 0.79\n",
    "        * Validation accuracy = 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random   #imports random module, which contains a variety of things to do with random numbers\n",
    "import skimage as sk   # imports scikit-image library that contains algorithms for image processing\n",
    "from skimage import transform   # imports transform module from skimage\n",
    "from skimage import util   # imports util module from skimage; provides utility functions to convert\n",
    "                           # both dtype and the data range.\n",
    "from scipy import ndarray   # we use scipy.ndarray to represent the image to transform.\n",
    "                            # This structure is convinient for computers as it is a 2D array\n",
    "                            # of image's pixels(RGB colors).\n",
    "import matplotlib.pyplot as plt   # matplotlib is python 2d plotting library\n",
    "                                  # pyplot is matplotlib's plotting framework \n",
    "%matplotlib inline   \n",
    "# Turns ON the inline plotting where graphs will be plotted inside the notebook\n",
    "import copy   # Importing copy module for deep copy operation\n",
    "import time   # Imports time module that handles various operations regarding time, its conversions and representations.\n",
    "from sklearn.utils import shuffle   # To shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Data Augumentation functions\n",
    "\n",
    "# A function to add image rotation\n",
    "def rand_rotation(image_array: ndarray,r = 25):\n",
    "    # pick a random degree of rotation between r% on the left and r% on the right\n",
    "    rand_degree = random.uniform(-r,r)\n",
    "    return sk.transform.rotate(image_array, rand_degree)\n",
    "\n",
    "# random.uniform(a, b)\n",
    "# Return a random floating point number N such that a <= N <= b for a <= b and b <= N <= a for b < a.\n",
    "# The end-point value b may or may not be included in the range depending on floating-point rounding \n",
    "# in the equation a + (b-a) * random().\n",
    "\n",
    "# skimage.transform.rotate(image, angle[, …])\n",
    "# Rotate image by a certain angle around its center.\n",
    "\n",
    "# Now a function to add some noise to the image.\n",
    "def rand_noise(image_array: ndarray):\n",
    "    return sk.util.random_noise(image_array)\n",
    "\n",
    "# This function adds random noise of various types to a floating-point image.\n",
    "\n",
    "# A function to do horizontal flip\n",
    "def horizontal_flip(image_array: ndarray):\n",
    "    return image_array[:, ::-1]\n",
    "\n",
    "# Using Extended slice: Extended slice offers to put a “step” field as [start,stop,step], \n",
    "# and giving no field as start and stop indicates default to 0 and string length respectively \n",
    "# and “-1” denotes starting from end and stop at the start, hence reversing string.\n",
    "\n",
    "\n",
    "# Similarly a function to do vertical flip using extended slice will be\n",
    "def vertical_flip(image_array: ndarray):\n",
    "    return image_array[::-1, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "n_classes = 10   # Number of classification categories\n",
    "\n",
    "def one_hot_encoding(z):\n",
    "    return np.eye(n_classes)[z.astype('int32')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0620 01:32:13.704144 140702374045504 deprecation_wrapper.py:118] From /home/sayan/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:95: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0620 01:32:13.705020 140702374045504 deprecation_wrapper.py:118] From /home/sayan/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:95: The name tf.AttrValue is deprecated. Please use tf.compat.v1.AttrValue instead.\n",
      "\n",
      "W0620 01:32:13.705705 140702374045504 deprecation_wrapper.py:118] From /home/sayan/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:95: The name tf.COMPILER_VERSION is deprecated. Please use tf.version.COMPILER_VERSION instead.\n",
      "\n",
      "W0620 01:32:13.706152 140702374045504 deprecation_wrapper.py:118] From /home/sayan/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:95: The name tf.CXX11_ABI_FLAG is deprecated. Please use tf.sysconfig.CXX11_ABI_FLAG instead.\n",
      "\n",
      "W0620 01:32:13.706576 140702374045504 deprecation_wrapper.py:118] From /home/sayan/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:95: The name tf.ConditionalAccumulator is deprecated. Please use tf.compat.v1.ConditionalAccumulator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28) \n",
      "x_test shape:  (10000, 28, 28) \n",
      "y_train shape:  (60000,) \n",
      "y_test shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "\n",
    "# from mlxtend.data import loadlocal_mnist\n",
    "# x_train,y_train = loadlocal_mnist(images_path = 'train-images.idx3-ubyte',labels_path = 'train-labels.idx1-ubyte')\n",
    "# x_test,y_test = loadlocal_mnist(images_path = 't10k-images.idx3-ubyte',labels_path = 't10k-labels.idx1-ubyte')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# using keras to load the fashion_mnist dataset\n",
    "\n",
    "print(\"x_train shape: \",x_train.shape, \"\\nx_test shape: \", x_test.shape, \"\\ny_train shape: \",y_train.shape, \"\\ny_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABVklEQVR4nG3SsUrDQBgH8P93uSQYS0RF66AOgiCIiNLncHNz9xUcfAFfwkfQ0UlwUKkODhZFq1CwDmlpG6M0NYl3n4upw903/fn/OO74OMJ4TuvFuxME1UOYs8eamTnn2XFF49SoRhNUFD9bB0cmcpQJ1pzNt2plJcqwjVSSIOF/bMLAXYAECSmV3Ck7WYaNlDSBFAu1aODCFysiMFQxY6AkEuyiYKlC486CBDjzBGtMGpiEWlVa3YDBwsAzn3X41g6VrjQNPIbUbv3GySTOjQfFiTfEaxvkF/fGSdz6Eg+PcOnO3BCuXSBJ4ThXFoyJkI/AbteCDjsoEkhyLbiqvQ4Q+2rJgrXcfwJeJK9YMFRuA4hcNWXBgLgD9AU5FszBl0ATzrcF+358AZzk8tmCA68NoJdR04KZ6AEYpCxNXJ5WPgQw9PbXy+7/365FnxrAXJj3Rn/VL2YQhjS/ZFdLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF7A0AA98D0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Visualizing the dataset\n",
    "\n",
    "from PIL import Image\n",
    "Image.fromarray(x_train[0])\n",
    "Image.fromarray(x_train[80])\n",
    "\n",
    "# img_index = 100\n",
    "# plt.imshow(x_train[img_index])   # plots the picture\n",
    "# plt.show()   # prints the picture that has been plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "# We normalize the data dimensions so that they are of approximately the same scale.\n",
    "# Here we are using min-max normalization.\n",
    "# x_train.max() = 255 = x_test.max()\n",
    "# x_train.min() = 0 = x_test.min()\n",
    "\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. number of transformations done on a single image = 4\n",
      "Batch 1 completed.\n",
      "Batch 2 completed.\n",
      "Batch 3 completed.\n",
      "Batch 4 completed.\n",
      "Batch 5 completed.\n",
      "Batch 6 completed.\n"
     ]
    }
   ],
   "source": [
    "# Image transformation\n",
    "\n",
    "# Making a dictionary of all the available transformations\n",
    "available_transformations = {'rotate':rand_rotation, \n",
    "                            'noise':rand_noise, \n",
    "                            'horizontal_flip':horizontal_flip, \n",
    "                            'vertical_flip':vertical_flip}\n",
    "\n",
    "# We will apply random number of transformations\n",
    "\n",
    "count = 1\n",
    "x_train_aug = copy.deepcopy(x_train)   # We perform deep copy so that the initial dataset remains unchanged\n",
    "\n",
    "max_transformations = 4 #random.randint(1, len(available_transformations))\n",
    "\n",
    "print(\"Max. number of transformations done on a single image =\", max_transformations)\n",
    "\n",
    "num_batch = 6   # Number of augumented batches required\n",
    "batch = 1\n",
    "\n",
    "aug = None\n",
    "\n",
    "while batch <= num_batch:\n",
    "    \n",
    "    num_transformations = 0\n",
    "    n_transformations = random.randint(1, max_transformations)   # randint gives random integers\n",
    "                                                                 # choosing a random number of transformations \n",
    "                                                                 # to be apply on a single batch\n",
    "    while num_transformations < n_transformations:\n",
    "        \n",
    "        key = random.choice(list(available_transformations))   # Here we choose the kind of transformations to apply\n",
    "                                                               # random.choice generates a random sample from \n",
    "                                                               # a given 1-D array\n",
    "        aug = available_transformations[key](x_train)   # The actual transformation process\n",
    "        num_transformations += 1\n",
    "        \n",
    "    x_train_aug = np.vstack((x_train_aug, aug))   # Stacking the training sets together in a row wise fashion   \n",
    "    print(\"Batch\", batch, \"completed.\")\n",
    "    count += 1\n",
    "    batch += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Image transformation\n",
    "\n",
    "# # Making a dictionary of all the available transformations\n",
    "# available_transformations = {'rotate':rand_rotation, \n",
    "#                             'noise':rand_noise, \n",
    "#                             'horizontal_flip':horizontal_flip, \n",
    "#                             'vertical_flip':vertical_flip}\n",
    "\n",
    "# n_transformations = 0\n",
    "# x_train_aug = copy.deepcopy(x_train)   # We perform deep copy so that the initial dataset remains unchanged\n",
    "# count = 1\n",
    "# for j in range(len(available_transformations)):\n",
    "#     n_transformations += 1 \n",
    "#     # randint gives random integers\n",
    "#     # choosing a random number of transformations to apply for a single image\n",
    "#     # print(\"Max. number of transformations done on a single image =\", n_transformations)\n",
    "\n",
    "#     num_batch = 3   # Number of augumented batches required\n",
    "#     batch = 1\n",
    "#     aug = None\n",
    "    \n",
    "\n",
    "#     while batch <= num_batch:\n",
    "    \n",
    "#         num_transformations = 0    \n",
    "#         while num_transformations < n_transformations:\n",
    "        \n",
    "#             key = random.choice(list(available_transformations))   # Here we choose the kind of transformations to apply\n",
    "#                                                                    # random.choice generates a random sample from \n",
    "#                                                                    # a given 1-D array\n",
    "#             aug = available_transformations[key](x_train)   # The actual transformation process\n",
    "#             num_transformations += 1\n",
    "        \n",
    "#         x_train_aug = np.vstack((x_train_aug, aug))   # Stacking the training sets together in a row wise fashion   \n",
    "#         print(\"Batch\", count, \"completed.\")\n",
    "#         count += 1\n",
    "#         batch += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_aug = np.tile(y_train,int(x_train_aug.shape[0]/x_train.shape[0]))   # Cloning the y_train into itself to match \n",
    "                                                                          # the corresponding augumented x_train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding of y_train and y_test\n",
    "y_train_aug = one_hot_encoding(y_train_aug)\n",
    "y_test = one_hot_encoding(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For shuffle\n",
    "x_train_aug, y_train_aug = shuffle(x_train_aug, y_train_aug, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_aug.shape, x_train.shape, y_train_aug.shape, y_test.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A final check of dimensions\n",
    "assert x_train_aug.shape == (count*x_train.shape[0], 28, 28)\n",
    "assert y_train_aug.shape == (count*y_train.shape[0], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining placeholder variables for the input images\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28], name = 'X')\n",
    "\n",
    "# Reshaping it into [num_images, img_height, img_width, num_channels]\n",
    "X = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# Placeholder variables for the true labels associated with the images\n",
    "Y = tf.placeholder(tf.float32, shape=[None,10], name = 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a new Convolution Layer\n",
    "\n",
    "def new_conv_layer(input_dataset, num_input_channels, filter_size, num_filters, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "    # Using \"with\" we can call anything that calls a context manager. \n",
    "    # A context manager provides a simple way to make sure all resources we use are properly cleaned up, \n",
    "    # regerdless of if the code returns or an exception is thrown.\n",
    "    # tf.variable_scope is a context manager for defining ops that creates variable(layers).\n",
    "    \n",
    "        # Shape of the filter-weights for the convolution\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "        # Create new weights (filters) with the given shape\n",
    "        weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "        # Outputs random values from a truncated normal distribution.\n",
    "        # The values whose magnitude is > (2*standard devaitions) from the mean are dropped and re-picked.\n",
    "        \n",
    "        # Create new biases, one for each filter\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_filters]))\n",
    "\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.conv2d(input=input_dataset, filter=weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        # This computes a 2D comvolution given a 4D input and filter tensors\n",
    "        # padding = \"SAME\" tries to pad evenly left and right, but if the amount of columns to be added is odd, \n",
    "        # it will add the extra column to the right.\n",
    "\n",
    "        # Add the biases to the results of the convolution.\n",
    "        layer += biases\n",
    "        \n",
    "        return layer, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a new Pooling Layer\n",
    "\n",
    "def new_pool_layer(input_dataset, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.max_pool(value=input_dataset, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        # Performs max pooling on the input\n",
    "        \n",
    "        return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a new ReLU Layer\n",
    "\n",
    "def new_relu_layer(input_dataset, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.relu(input_dataset)\n",
    "        # Computes ReLU operation on the input\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a new Fully connected Layer\n",
    "\n",
    "def new_fc_layer(input_dataset, num_inputs, num_outputs, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "\n",
    "        # Create new weights and biases.\n",
    "        weights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.05))\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "        \n",
    "        # Multiply the input and weights, and then add the bias-values.\n",
    "        layer = tf.matmul(input_dataset, weights) + biases\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function for Batch normalization\n",
    "\n",
    "# training = 1\n",
    "\n",
    "# # x = tf.layers.dense(input_x, units=100)\n",
    "# # x = tf.layers.batch_normalization(x, training=training)\n",
    "# # x = tf.nn.relu(x)\n",
    "\n",
    "# # update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "# # with tf.control_dependencies(update_ops):\n",
    "# #   train_op = optimizer.minimize(loss)\n",
    "\n",
    "# # dataset = True\n",
    "\n",
    "# def batch_norm(input_dataset, dataset, name):\n",
    "    \n",
    "#     with tf.variable_scope(name) as scope:\n",
    "# #         layer = tf.Variable(tf.layers.batch_normalization(input_dataset, training = bool(dataset)))\n",
    "#         layer = tf.layers.batch_normalization(input_dataset, training = bool(dataset))\n",
    "    \n",
    "#     return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding Dropout layer\n",
    "\n",
    "def new_dropout_layer(input_dataset,dataset,name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "#         layer = tf.Variable(tf.layers.dropout(input_dataset, rate=0.5, training = bool(dataset)))\n",
    "        layer = tf.layers.dropout(input_dataset, rate=0.2, training = bool(dataset))\n",
    "        \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a CNN with Batch Normalization and Dropout layers\n",
    "\n",
    "# Convolutional Layer 1\n",
    "layer_conv1, weights_conv1 = new_conv_layer(input_dataset=X, num_input_channels=1, filter_size=5, num_filters=6, name =\"conv1\")\n",
    "\n",
    "# Pooling Layer 1\n",
    "layer_pool1 = new_pool_layer(layer_conv1, name=\"pool1\")\n",
    "\n",
    "# Batch Normalization 1\n",
    "# layer_batnorm1 = batch_norm(layer_pool1, training, name=\"bnorm1\")\n",
    "layer_batnorm1 = tf.layers.batch_normalization(layer_pool1, training=bool(training))\n",
    "\n",
    "# RelU layer 1\n",
    "layer_relu1 = new_relu_layer(layer_batnorm1, name=\"relu1\")\n",
    "\n",
    "# Dropout Layer 1\n",
    "layer_dropout1 = new_dropout_layer(layer_relu1, training, name=\"dout1\")\n",
    "\n",
    "# Convolutional Layer 2\n",
    "layer_conv2, weights_conv2 = new_conv_layer(input_dataset=layer_dropout1, num_input_channels=6, filter_size=5, num_filters=16, name= \"conv2\")\n",
    "\n",
    "# Pooling Layer 2\n",
    "layer_pool2 = new_pool_layer(layer_conv2, name=\"pool2\")\n",
    "\n",
    "# Batch Normalization 2\n",
    "# layer_batnorm2 = batch_norm(layer_pool2, training, name=\"bnorm2\")\n",
    "layer_batnorm2 = tf.layers.batch_normalization(layer_pool2, training=bool(training))\n",
    "\n",
    "# RelU layer 2\n",
    "layer_relu2 = new_relu_layer(layer_batnorm2, name=\"relu2\")\n",
    "\n",
    "# Dropout Layer 2\n",
    "layer_dropout2 = new_dropout_layer(layer_relu2, training, name=\"dout2\")\n",
    "\n",
    "# Flatten Layer\n",
    "num_features = layer_relu2.get_shape()[1:4].num_elements()\n",
    "layer_flat = tf.reshape(layer_dropout2, [-1, num_features])\n",
    "\n",
    "# Fully-Connected Layer 1\n",
    "layer_fc1 = new_fc_layer(layer_flat, num_inputs=num_features, num_outputs=128, name=\"fc1\")\n",
    "\n",
    "# Batch Normalization 3\n",
    "# layer_batnorm3 = batch_norm(layer_fc1, training, name=\"bnorm3\")\n",
    "layer_batnorm3 = tf.layers.batch_normalization(layer_fc1, training=bool(training))\n",
    "\n",
    "# RelU layer 3\n",
    "layer_relu3 = new_relu_layer(layer_batnorm3, name=\"relu3\")\n",
    "\n",
    "# Dropout Layer 3\n",
    "layer_dropout3 = new_dropout_layer(layer_relu3, training, name=\"dout3\")\n",
    "\n",
    "# Fully-Connected Layer 2\n",
    "layer_fc2 = new_fc_layer(input_dataset=layer_dropout3, num_inputs=128, num_outputs=10, name=\"fc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Softmax function to normalize the output\n",
    "with tf.variable_scope(\"Softmax\"):\n",
    "    y_pred = tf.nn.softmax(layer_fc2)\n",
    "#     y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred#, y_pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Cross entropy cost function\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=Y)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "# tf.nn.softmax_cross_entropy_with_logits computes the cross entropy of the function after applying the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost, cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-3   # Learning rate for the upgraded CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Adam Optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=alpha).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    #print(y_pred.shape,Y.shape)\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(Y,1))   # Returns the truth value of (y_pred == Y) element-wise.\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    # tf.cast: Casts a tensor to a new type.\n",
    "    # tf.reduce_mean: Computes the mean of elements across dimensions of a tensor.\n",
    "#     correct_prediction = tf.equal(y_pred,Y)   # Returns the truth value of (y_pred == Y) element-wise.\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(\"Training_FileWriter/\")\n",
    "writer1 = tf.summary.FileWriter(\"Validation_FileWriter/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cost and accuracy to summary\n",
    "tf.summary.scalar('loss', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decay_learning_rate(previous_acc, new_acc, learning_rate):\n",
    "#     '''Deacy learning rate function\n",
    "#     Args:\n",
    "#         acc : float, accuracy to check\n",
    "#     Returns:\n",
    "    \n",
    "#     '''\n",
    "#     if (previous_acc-new_acc)<= 0.01:\n",
    "#         learning_rate = learning_rate/10\n",
    "    \n",
    "#     return learning_rate\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "     \n",
    "    intial_time = time.gmtime()   \n",
    "    \n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        training = 1   # boolean value True for training set\n",
    "        start_time = time.time()   # This function is used to count the number of seconds elapsed since the epoch.\n",
    "        train_accuracy = 0\n",
    "        i = 1\n",
    "        for batch in range(0, int(len(x_train_aug)/batch_size)):\n",
    "            \n",
    "            # Get a batch of images and labels\n",
    "            x_batch = x_train_aug[((i-1)*batch_size):(i*batch_size),:,:]\n",
    "            y_true_batch = y_train_aug[((i-1)*batch_size):(i*batch_size), :]\n",
    "            \n",
    "            # Put the batch into a dict with the proper names for placeholder variables\n",
    "            feed_dict_train = {x: x_batch, Y: y_true_batch}\n",
    "            \n",
    "            # Run the optimizer using this batch of training data.\n",
    "            sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Calculate the accuracy on the batch of training data\n",
    "            train_accuracy += sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Generate summary with the current batch of data and write to file\n",
    "            summ = sess.run(merged_summary, feed_dict=feed_dict_train)\n",
    "            writer.add_summary(summ, epoch*int(len(x_train_aug)/batch_size) + batch)\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "          \n",
    "        train_accuracy /= int(len(x_train_aug)/batch_size)   # The training accuracy is obtained by dividing \n",
    "                                                             # the result by the number of epochs\n",
    "        training = 0   # boolean value False for test set\n",
    "        \n",
    "        # Generate summary and validate the model on the entire validation set\n",
    "        summ, vali_accuracy = sess.run([merged_summary, accuracy], feed_dict={x:x_test, Y:y_test})\n",
    "#         apha = decay_learning_rate()\n",
    "        writer1.add_summary(summ, epoch)\n",
    "        \n",
    "\n",
    "        end_time = time.time()\n",
    "        closing_time = time.gmtime()\n",
    "        print(\"Epoch \"+str(epoch+1)+\" completed : Time usage \"+str(int(end_time-start_time))+\" seconds\")\n",
    "        print(\"\\tAccuracy:\")\n",
    "        print (\"\\t- Training Accuracy:\\t{}\".format(train_accuracy))\n",
    "        print (\"\\t- Validation Accuracy:\\t{}\".format(vali_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Accuracy after \" + str(epoch+1) + \" Epochs:\")\n",
    "print (\"- Training Accuracy:\\t{}\".format(train_accuracy))\n",
    "print (\"- Validation Accuracy:\\t{}\".format(vali_accuracy))\n",
    "print (\"/nTotal time to run the session = \" + str(initial_time-closing_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
