{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5v1.0\n",
    "\n",
    "# Implementing CNN using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents :\n",
    "\n",
    "* Data extraction\n",
    "* Visualizing the data\n",
    "* Defining Data Augumentation functions\n",
    "* Data engineeering (one hot encoding)\n",
    "* Applying Image transformations\n",
    "* Defining functons for Convolution, Max pool, ReLU, Flatten and Fully connected layers.\n",
    "* Setting the sequence of the execution of Layers\n",
    "* Running the session\n",
    "* The hyperparameters :\n",
    "    * Number of Epochs: 100\n",
    "    * Batch size: 100\n",
    "    * Number of augumented batches: 6\n",
    "    * Learning rate: alpha = 1e-4\n",
    "    * Convolution layers: 3, filter size = 5*5, strides = [1,1,1,1] \n",
    "    * Max pool layers: 3, filter size = 2*2, strides = [1,2,2,1]\n",
    "    * ReLU layers: 3\n",
    "    * Fully connected layers: 2\n",
    "    * Flatten layer: 1\n",
    "* The layer sequence of the architecture: conv1 > pool1 > relu1 > conv2 > pool2 > relu2 > flatten > fc1 > relu3 > fc2\n",
    "* In 10 epochs:\n",
    "        * Training accuracy = 0.66\n",
    "        * Validation accuracy = 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random   #imports random module, which contains a variety of things to do with random numbers\n",
    "import skimage as sk   # imports scikit-image library that contains algorithms for image processing\n",
    "from skimage import transform   # imports transform module from skimage\n",
    "from skimage import util   # imports util module from skimage; provides utility functions to convert\n",
    "                           # both dtype and the data range.\n",
    "from scipy import ndarray   # we use scipy.ndarray to represent the image to transform.\n",
    "                            # This structure is convinient for computers as it is a 2D array\n",
    "                            # of image's pixels(RGB colors).\n",
    "import matplotlib.pyplot as plt   # matplotlib is python 2d plotting library\n",
    "                                  # pyplot is matplotlib's plotting framework \n",
    "%matplotlib inline   \n",
    "# Turns ON the inline plotting where graphs will be plotted inside the notebook\n",
    "import copy   # Importing copy module for deep copy operation\n",
    "import time   # Imports time module that handles various operations regarding time, its conversions and representations.\n",
    "from sklearn.utils import shuffle   # To shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Data Augumentation functions\n",
    "\n",
    "# A function to add image rotation\n",
    "def rand_rotation(image_array: ndarray,r = 25):\n",
    "    # pick a random degree of rotation between r% on the left and r% on the right\n",
    "    rand_degree = random.uniform(-r,r)\n",
    "    return sk.transform.rotate(image_array, rand_degree)\n",
    "\n",
    "# random.uniform(a, b)\n",
    "# Return a random floating point number N such that a <= N <= b for a <= b and b <= N <= a for b < a.\n",
    "# The end-point value b may or may not be included in the range depending on floating-point rounding \n",
    "# in the equation a + (b-a) * random().\n",
    "\n",
    "# skimage.transform.rotate(image, angle[, …])\n",
    "# Rotate image by a certain angle around its center.\n",
    "\n",
    "# Now a function to add some noise to the image.\n",
    "def rand_noise(image_array: ndarray):\n",
    "    return sk.util.random_noise(image_array)\n",
    "\n",
    "# This function adds random noise of various types to a floating-point image.\n",
    "\n",
    "# A function to do horizontal flip\n",
    "def horizontal_flip(image_array: ndarray):\n",
    "    return image_array[:, ::-1]\n",
    "\n",
    "# Using Extended slice: Extended slice offers to put a “step” field as [start,stop,step], \n",
    "# and giving no field as start and stop indicates default to 0 and string length respectively \n",
    "# and “-1” denotes starting from end and stop at the start, hence reversing string.\n",
    "\n",
    "\n",
    "# Similarly a function to do vertical flip using extended slice will be\n",
    "def vertical_flip(image_array: ndarray):\n",
    "    return image_array[::-1, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "n_classes = 10   # Number of classification categories\n",
    "\n",
    "def one_hot_encoding(z):\n",
    "    return np.eye(n_classes)[z.astype('int32')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# # Ignore the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0620 01:00:44.570425 140377916077888 deprecation_wrapper.py:118] From /home/sayan/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:95: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0620 01:00:44.571241 140377916077888 deprecation_wrapper.py:118] From /home/sayan/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:95: The name tf.AttrValue is deprecated. Please use tf.compat.v1.AttrValue instead.\n",
      "\n",
      "W0620 01:00:44.571741 140377916077888 deprecation_wrapper.py:118] From /home/sayan/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:95: The name tf.COMPILER_VERSION is deprecated. Please use tf.version.COMPILER_VERSION instead.\n",
      "\n",
      "W0620 01:00:44.572230 140377916077888 deprecation_wrapper.py:118] From /home/sayan/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:95: The name tf.CXX11_ABI_FLAG is deprecated. Please use tf.sysconfig.CXX11_ABI_FLAG instead.\n",
      "\n",
      "W0620 01:00:44.572745 140377916077888 deprecation_wrapper.py:118] From /home/sayan/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:95: The name tf.ConditionalAccumulator is deprecated. Please use tf.compat.v1.ConditionalAccumulator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28) \n",
      "x_test shape:  (10000, 28, 28) \n",
      "y_train shape:  (60000,) \n",
      "y_test shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "\n",
    "# from mlxtend.data import loadlocal_mnist\n",
    "# x_train,y_train = loadlocal_mnist(images_path = 'train-images.idx3-ubyte',labels_path = 'train-labels.idx1-ubyte')\n",
    "# x_test,y_test = loadlocal_mnist(images_path = 't10k-images.idx3-ubyte',labels_path = 't10k-labels.idx1-ubyte')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# using keras to load the fashion_mnist dataset\n",
    "\n",
    "print(\"x_train shape: \",x_train.shape, \"\\nx_test shape: \", x_test.shape, \"\\ny_train shape: \",y_train.shape, \"\\ny_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABVklEQVR4nG3SsUrDQBgH8P93uSQYS0RF66AOgiCIiNLncHNz9xUcfAFfwkfQ0UlwUKkODhZFq1CwDmlpG6M0NYl3n4upw903/fn/OO74OMJ4TuvFuxME1UOYs8eamTnn2XFF49SoRhNUFD9bB0cmcpQJ1pzNt2plJcqwjVSSIOF/bMLAXYAECSmV3Ck7WYaNlDSBFAu1aODCFysiMFQxY6AkEuyiYKlC486CBDjzBGtMGpiEWlVa3YDBwsAzn3X41g6VrjQNPIbUbv3GySTOjQfFiTfEaxvkF/fGSdz6Eg+PcOnO3BCuXSBJ4ThXFoyJkI/AbteCDjsoEkhyLbiqvQ4Q+2rJgrXcfwJeJK9YMFRuA4hcNWXBgLgD9AU5FszBl0ATzrcF+358AZzk8tmCA68NoJdR04KZ6AEYpCxNXJ5WPgQw9PbXy+7/365FnxrAXJj3Rn/VL2YQhjS/ZFdLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FAC1577A9B0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Visualizing the dataset\n",
    "\n",
    "from PIL import Image\n",
    "Image.fromarray(x_train[0])\n",
    "Image.fromarray(x_train[80])\n",
    "\n",
    "# img_index = 100\n",
    "# plt.imshow(x_train[img_index])   # plots the picture\n",
    "# plt.show()   # prints the picture that has been plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "# We normalize the data dimensions so that they are of approximately the same scale.\n",
    "# Here we are using min-max normalization.\n",
    "# x_train.max() = 255 = x_test.max()\n",
    "# x_train.min() = 0 = x_test.min()\n",
    "\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os   # The OS module in python provides functions for interacting with the operating system\n",
    "\n",
    "# # The nummber of files to generate\n",
    "# n_files = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. number of transformations done on a single image = 4\n",
      "Batch 1 completed.\n",
      "Batch 2 completed.\n",
      "Batch 3 completed.\n",
      "Batch 4 completed.\n",
      "Batch 5 completed.\n",
      "Batch 6 completed.\n"
     ]
    }
   ],
   "source": [
    "# Image transformation\n",
    "\n",
    "# Making a dictionary of all the available transformations\n",
    "available_transformations = {'rotate':rand_rotation, \n",
    "                            'noise':rand_noise, \n",
    "                            'horizontal_flip':horizontal_flip, \n",
    "                            'vertical_flip':vertical_flip}\n",
    "\n",
    "# We will apply random number of transformations\n",
    "\n",
    "count = 1\n",
    "x_train_aug = copy.deepcopy(x_train)   # We perform deep copy so that the initial dataset remains unchanged\n",
    "\n",
    "max_transformations = 4 #random.randint(1, len(available_transformations))\n",
    "\n",
    "print(\"Max. number of transformations done on a single image =\", max_transformations)\n",
    "\n",
    "num_batch = 6   # Number of augumented batches required\n",
    "batch = 1\n",
    "\n",
    "aug = None\n",
    "\n",
    "while batch <= num_batch:\n",
    "    \n",
    "    num_transformations = 0\n",
    "    n_transformations = random.randint(1, max_transformations)   # randint gives random integers\n",
    "                                                                 # choosing a random number of transformations \n",
    "                                                                 # to be apply on a single batch\n",
    "    while num_transformations < n_transformations:\n",
    "        \n",
    "        key = random.choice(list(available_transformations))   # Here we choose the kind of transformations to apply\n",
    "                                                               # random.choice generates a random sample from \n",
    "                                                               # a given 1-D array\n",
    "        aug = available_transformations[key](x_train)   # The actual transformation process\n",
    "        num_transformations += 1\n",
    "        \n",
    "    x_train_aug = np.vstack((x_train_aug, aug))   # Stacking the training sets together in a row wise fashion   \n",
    "    print(\"Batch\", batch, \"completed.\")\n",
    "    count += 1\n",
    "    batch += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Image transformation\n",
    "\n",
    "# # Making a dictionary of all the available transformations\n",
    "# available_transformations = {'rotate':rand_rotation, \n",
    "#                             'noise':rand_noise, \n",
    "#                             'horizontal_flip':horizontal_flip, \n",
    "#                             'vertical_flip':vertical_flip}\n",
    "\n",
    "# n_transformations = 0\n",
    "# x_train_aug = copy.deepcopy(x_train)   # We perform deep copy so that the initial dataset remains unchanged\n",
    "# count = 1\n",
    "# for j in range(len(available_transformations)):\n",
    "#     n_transformations += 1 \n",
    "#     # randint gives random integers\n",
    "#     # choosing a random number of transformations to apply for a single image\n",
    "#     # print(\"Max. number of transformations done on a single image =\", n_transformations)\n",
    "\n",
    "#     num_batch = 3   # Number of augumented batches required\n",
    "#     batch = 1\n",
    "#     aug = None\n",
    "    \n",
    "\n",
    "#     while batch <= num_batch:\n",
    "    \n",
    "#         num_transformations = 0    \n",
    "#         while num_transformations < n_transformations:\n",
    "        \n",
    "#             key = random.choice(list(available_transformations))   # Here we choose the kind of transformations to apply\n",
    "#                                                                    # random.choice generates a random sample from \n",
    "#                                                                    # a given 1-D array\n",
    "#             aug = available_transformations[key](x_train)   # The actual transformation process\n",
    "#             num_transformations += 1\n",
    "        \n",
    "#         x_train_aug = np.vstack((x_train_aug, aug))   # Stacking the training sets together in a row wise fashion   \n",
    "#         print(\"Batch\", count, \"completed.\")\n",
    "#         count += 1\n",
    "#         batch += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_aug = np.tile(y_train,int(x_train_aug.shape[0]/x_train.shape[0]))   # Cloning the y_train into itself to match \n",
    "                                                                          # the corresponding augumented x_train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding of y_train and y_test\n",
    "y_train_aug = one_hot_encoding(y_train_aug)\n",
    "y_test = one_hot_encoding(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For shuffle\n",
    "x_train_aug, y_train_aug = shuffle(x_train_aug, y_train_aug, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((420000, 28, 28), (60000, 28, 28), (420000, 10), (10000, 10), (10000, 28, 28))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_aug.shape, x_train.shape, y_train_aug.shape, y_test.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A final check of dimensions\n",
    "assert x_train_aug.shape == (count*x_train.shape[0], 28, 28)\n",
    "assert y_train_aug.shape == (count*y_train.shape[0], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = np.reshape(x_train_aug, [-1,14,14,1])\n",
    "# z.shape, x_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining placeholder variables for the input images\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28], name = 'X')\n",
    "\n",
    "# Reshaping it into [num_images, img_height, img_width, num_channels]\n",
    "X = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# Placeholder variables for the true labels associated with the images\n",
    "Y = tf.placeholder(tf.float32, shape=[None,10], name = 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Reshape:0' shape=(?, 28, 28, 1) dtype=float32>,\n",
       " <tf.Tensor 'Y:0' shape=(?, 10) dtype=float32>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a new Convolution Layer\n",
    "\n",
    "def new_conv_layer(input_dataset, num_input_channels, filter_size, num_filters, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "    # Using \"with\" we can call anything that calls a context manager. \n",
    "    # A context manager provides a simple way to make sure all resources we use are properly cleaned up, \n",
    "    # regerdless of if the code returns or an exception is thrown.\n",
    "    # tf.variable_scope is a context manager for defining ops that creates variable(layers).\n",
    "    \n",
    "        # Shape of the filter-weights for the convolution\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "        # Create new weights (filters) with the given shape\n",
    "        weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "        # Outputs random values from a truncated normal distribution.\n",
    "        # The values whose magnitude is > (2*standard devaitions) from the mean are dropped and re-picked.\n",
    "        \n",
    "        # Create new biases, one for each filter\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_filters]))\n",
    "\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.conv2d(input=input_dataset, filter=weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        # This computes a 2D comvolution given a 4D input and filter tensors\n",
    "        # padding = \"SAME\" tries to pad evenly left and right, but if the amount of columns to be added is odd, \n",
    "        # it will add the extra column to the right.\n",
    "\n",
    "        # Add the biases to the results of the convolution.\n",
    "        layer += biases\n",
    "        \n",
    "        return layer, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420000, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a new Pooling Layer\n",
    "\n",
    "def new_pool_layer(input_dataset, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.max_pool(value=input_dataset, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        # Performs max pooling on the input\n",
    "        \n",
    "        return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a new ReLU Layer\n",
    "\n",
    "def new_relu_layer(input_dataset, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.relu(input_dataset)\n",
    "        # Computes ReLU operation on the input\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a new Fully connected Layer\n",
    "\n",
    "def new_fc_layer(input_dataset, num_inputs, num_outputs, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "\n",
    "        # Create new weights and biases.\n",
    "        weights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.05))\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "        \n",
    "        # Multiply the input and weights, and then add the bias-values.\n",
    "        layer = tf.matmul(input_dataset, weights) + biases\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a CNN\n",
    "\n",
    "# Convolutional Layer 1\n",
    "layer_conv1, weights_conv1 = new_conv_layer(input_dataset=X, num_input_channels=1, filter_size=5, num_filters=6, name =\"conv1\")\n",
    "\n",
    "# Pooling Layer 1\n",
    "layer_pool1 = new_pool_layer(layer_conv1, name=\"pool1\")\n",
    "\n",
    "# RelU layer 1\n",
    "layer_relu1 = new_relu_layer(layer_pool1, name=\"relu1\")\n",
    "\n",
    "# Convolutional Layer 2\n",
    "layer_conv2, weights_conv2 = new_conv_layer(input_dataset=layer_relu1, num_input_channels=6, filter_size=5, num_filters=16, name= \"conv2\")\n",
    "\n",
    "# Pooling Layer 2\n",
    "layer_pool2 = new_pool_layer(layer_conv2, name=\"pool2\")\n",
    "\n",
    "# RelU layer 2\n",
    "layer_relu2 = new_relu_layer(layer_pool2, name=\"relu2\")\n",
    "\n",
    "# Flatten Layer\n",
    "num_features = layer_relu2.get_shape()[1:4].num_elements()\n",
    "layer_flat = tf.reshape(layer_relu2, [-1, num_features])\n",
    "\n",
    "# Fully-Connected Layer 1\n",
    "layer_fc1 = new_fc_layer(layer_flat, num_inputs=num_features, num_outputs=128, name=\"fc1\")\n",
    "\n",
    "# RelU layer 3\n",
    "layer_relu3 = new_relu_layer(layer_fc1, name=\"relu3\")\n",
    "\n",
    "# Fully-Connected Layer 2\n",
    "layer_fc2 = new_fc_layer(input_dataset=layer_relu3, num_inputs=128, num_outputs=10, name=\"fc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Softmax function to normalize the output\n",
    "with tf.variable_scope(\"Softmax\"):\n",
    "    y_pred = tf.nn.softmax(layer_fc2)\n",
    "#     y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax/Softmax:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred#, y_pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 01:01:29.382840 140377916077888 deprecation.py:323] From <ipython-input-28-9839ac1548b8>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the Cross entropy cost function\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=Y)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "# tf.nn.softmax_cross_entropy_with_logits computes the cross entropy of the function after applying the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'cross_ent/Mean:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'cross_ent/softmax_cross_entropy_with_logits_sg/Reshape_2:0' shape=(?,) dtype=float32>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost, cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-4   # Learning rate for the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Adam Optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=alpha).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'optimizer/Adam' type=NoOp>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    #print(y_pred.shape,Y.shape)\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(Y,1))   # Returns the truth value of (y_pred == Y) element-wise.\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    # tf.cast: Casts a tensor to a new type.\n",
    "    # tf.reduce_mean: Computes the mean of elements across dimensions of a tensor.\n",
    "#     correct_prediction = tf.equal(y_pred,Y)   # Returns the truth value of (y_pred == Y) element-wise.\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy/Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(\"Training_FileWriter/\")\n",
    "writer1 = tf.summary.FileWriter(\"Validation_FileWriter/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cost and accuracy to summary\n",
    "tf.summary.scalar('loss', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed : Time usage 144 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.5380809496751143\n",
      "\t- Validation Accuracy:\t0.6840999722480774\n",
      "Epoch 2 completed : Time usage 144 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.6074666659888767\n",
      "\t- Validation Accuracy:\t0.7425000071525574\n",
      "Epoch 3 completed : Time usage 144 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.6282833331184727\n",
      "\t- Validation Accuracy:\t0.7771999835968018\n",
      "Epoch 4 completed : Time usage 144 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.6400142864528157\n",
      "\t- Validation Accuracy:\t0.7975000143051147\n",
      "Epoch 5 completed : Time usage 157 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.6479904770993051\n",
      "\t- Validation Accuracy:\t0.8108999729156494\n",
      "Epoch 6 completed : Time usage 153 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.6534023821708702\n",
      "\t- Validation Accuracy:\t0.8230999708175659\n",
      "Epoch 7 completed : Time usage 156 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.6580880963518506\n",
      "\t- Validation Accuracy:\t0.8330000042915344\n",
      "Epoch 8 completed : Time usage 152 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.6619666678848721\n",
      "\t- Validation Accuracy:\t0.8385999798774719\n",
      "Epoch 9 completed : Time usage 151 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.6652333346009255\n",
      "\t- Validation Accuracy:\t0.8410000205039978\n",
      "Epoch 10 completed : Time usage 150 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.6684357154369355\n",
      "\t- Validation Accuracy:\t0.845300018787384\n",
      "Epoch 11 completed : Time usage 148 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.6709142870846249\n",
      "\t- Validation Accuracy:\t0.8500999808311462\n",
      "Epoch 12 completed : Time usage 152 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.6729809537671861\n",
      "\t- Validation Accuracy:\t0.8529000282287598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 01:31:48.473259 140377916077888 deprecation_wrapper.py:118] From /home/sayan/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:10: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-7cfbda6dacc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Generate summary with the current batch of data and write to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0msumm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    intial_time = time.gmtime()\n",
    "    \n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        start_time = time.time()   # This function is used to count the number of seconds elapsed since the epoch.\n",
    "        train_accuracy = 0\n",
    "        i = 1\n",
    "        for batch in range(0, int(len(x_train_aug)/batch_size)):\n",
    "            \n",
    "            # Get a batch of images and labels\n",
    "            x_batch = x_train_aug[((i-1)*batch_size):(i*batch_size),:,:]\n",
    "            y_true_batch = y_train_aug[((i-1)*batch_size):(i*batch_size), :]\n",
    "            \n",
    "            # Put the batch into a dict with the proper names for placeholder variables\n",
    "            feed_dict_train = {x: x_batch, Y: y_true_batch}\n",
    "            \n",
    "            # Run the optimizer using this batch of training data.\n",
    "            sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Calculate the accuracy on the batch of training data\n",
    "            train_accuracy += sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Generate summary with the current batch of data and write to file\n",
    "            summ = sess.run(merged_summary, feed_dict=feed_dict_train)\n",
    "            writer.add_summary(summ, epoch*int(len(x_train_aug)/batch_size) + batch)\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "          \n",
    "        train_accuracy /= int(len(x_train_aug)/batch_size)   # The training accuracy is obtained by dividing \n",
    "                                                             # the result by the number of epochs\n",
    "        \n",
    "        # Generate summary and validate the model on the entire validation set\n",
    "        summ, vali_accuracy = sess.run([merged_summary, accuracy], feed_dict={x:x_test, Y:y_test})\n",
    "        writer1.add_summary(summ, epoch)\n",
    "        \n",
    "\n",
    "        end_time = time.time()\n",
    "        closing_time = time.gmtime()\n",
    "        \n",
    "        print(\"Epoch \"+str(epoch+1)+\" completed : Time usage \"+str(int(end_time-start_time))+\" seconds\")\n",
    "        print(\"\\tAccuracy:\")\n",
    "        print (\"\\t- Training Accuracy:\\t{}\".format(train_accuracy))\n",
    "        print (\"\\t- Validation Accuracy:\\t{}\".format(vali_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Accuracy after \" + str(epoch+1) + \" Epochs:\")\n",
    "print (\"- Training Accuracy:\\t{}\".format(train_accuracy))\n",
    "print (\"- Validation Accuracy:\\t{}\".format(vali_accuracy))\n",
    "print (\"/nTotal time to run the session = \" + str(initial_time-closing_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
