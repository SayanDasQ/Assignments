{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the data\n",
    "dataset = pd.read_csv('/home/sayan/Documents/Assignment_3files/sonar.all-data', header = None)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 60)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dataset.iloc[:,:60]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ = dataset.iloc[:,-1]\n",
    "y_\n",
    "len(y_)\n",
    "y_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import Series\n",
    "Y = []\n",
    "for i in range(len(y_)):\n",
    "    if y_[i] == \"R\":\n",
    "        Y.append(0)\n",
    "    else:\n",
    "        Y.append(1)\n",
    "        \n",
    "y = Series(Y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "x_train = sc.fit_transform(x_train)  \n",
    "x_test = sc.transform(x_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the Algorithm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 20, random_state = 0)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.79        21\n",
      "           1       0.76      0.90      0.83        21\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        42\n",
      "   macro avg       0.82      0.81      0.81        42\n",
      "weighted avg       0.82      0.81      0.81        42\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  6]\n",
      " [ 2 19]]\n",
      "\n",
      "Accuracy Score:\n",
      "0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the Algorithm\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff78ad01be0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "sn.heatmap(confusion_matrix(y_test,y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 20,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 0,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(classifier.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [1, 3, 5, 7, 10, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(1, 10, num = 5 )]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.3min finished\n",
      "/home/sayan/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [1, 3, 5, 7, 10, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the random grid to search for best hyperparameters\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "cl_random = RandomizedSearchCV(estimator = classifier, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=0, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "cl_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating random search\n",
    "def evaluate(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    errors = abs(y_pred - y_test)\n",
    "    accuracy = (accuracy_score(y_test, y_pred))*100\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f}'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.1905\n",
      "Accuracy = 80.95%.\n"
     ]
    }
   ],
   "source": [
    "base_model_accuracy = evaluate(classifier, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.0714\n",
      "Accuracy = 92.86%.\n"
     ]
    }
   ],
   "source": [
    "classifier_random = cl_random.best_estimator_\n",
    "\n",
    "random_accuracy_score = evaluate(classifier_random, x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of 12.82%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy_score - base_model_accuracy) / random_accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import support vector classifier\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='rbf')\n",
    "\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84        21\n",
      "           1       0.80      0.95      0.87        21\n",
      "\n",
      "   micro avg       0.86      0.86      0.86        42\n",
      "   macro avg       0.87      0.86      0.86        42\n",
      "weighted avg       0.87      0.86      0.86        42\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16  5]\n",
      " [ 1 20]]\n",
      "\n",
      "Accuracy Score:\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the Algorithm\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'C': 1.0,\n",
      " 'cache_size': 200,\n",
      " 'class_weight': None,\n",
      " 'coef0': 0.0,\n",
      " 'decision_function_shape': 'ovr',\n",
      " 'degree': 3,\n",
      " 'gamma': 'auto_deprecated',\n",
      " 'kernel': 'rbf',\n",
      " 'max_iter': -1,\n",
      " 'probability': False,\n",
      " 'random_state': None,\n",
      " 'shrinking': True,\n",
      " 'tol': 0.001,\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# Look at parameters used by SVM\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(clf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff78ab9f6d8>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.heatmap(confusion_matrix(y_test,y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svc_param_selection(x_train, y_train, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma': gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv = nfolds, verbose=2,  n_jobs = -1)\n",
    "    grid_search.fit(x_train,y_train)\n",
    "    #grid_search.best_params_\n",
    "    return grid_search#.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  60 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.2s finished\n",
      "/home/sayan/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "svc_random = svc_param_selection(x_train, y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.01}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.1429\n",
      "Accuracy = 85.71%.\n"
     ]
    }
   ],
   "source": [
    "svc_base_model_accuracy = evaluate(clf, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.0952\n",
      "Accuracy = 90.48%.\n"
     ]
    }
   ],
   "source": [
    "svc_classifier_random = svc_random.best_estimator_\n",
    "\n",
    "random_accuracy_score = evaluate(svc_classifier_random, x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of 5.26%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy_score - svc_base_model_accuracy) / random_accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,\n",
    "                               max_depth=3, min_samples_leaf=5)\n",
    "dc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78        21\n",
      "           1       0.77      0.81      0.79        21\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        42\n",
      "   macro avg       0.79      0.79      0.79        42\n",
      "weighted avg       0.79      0.79      0.79        42\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16  5]\n",
      " [ 4 17]]\n",
      "\n",
      "Accuracy Score:\n",
      "0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the Algorithm\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': 3,\n",
      " 'max_features': None,\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'presort': False,\n",
      " 'random_state': 100,\n",
      " 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# Look at parameters used by Gini\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(dc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [int(x) for x in np.linspace(start = 1, stop = 10, num = 5)]\n",
    "min_samples_split = [int(x) for x in np.linspace(start = 2, stop = 20, num = 5)]\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 10, num = 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dc = {\"max_depth\":max_depth, \"min_samples_split\":min_samples_split, \"min_samples_leaf\":min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_random = RandomizedSearchCV(estimator = dc, param_distributions = param_grid_dc, n_iter = 100, cv = 3, verbose=2, random_state=0, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    0.3s finished\n",
      "/home/sayan/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best'),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'max_depth': [1, 3, 5, 7, 10], 'min_samples_split': [2, 6, 11, 15, 20], 'min_samples_leaf': [1, 3, 5, 7, 10]},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 6, 'min_samples_leaf': 5, 'max_depth': 10}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.2143\n",
      "Accuracy = 78.57%.\n"
     ]
    }
   ],
   "source": [
    "dc_base_model_accuracy = evaluate(dc, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.0238\n",
      "Accuracy = 97.62%.\n"
     ]
    }
   ],
   "source": [
    "dc_classifier_random = dc_random.best_estimator_\n",
    "\n",
    "dc_random_accuracy_score = evaluate(dc_random, x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of 19.51%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (dc_random_accuracy_score - dc_base_model_accuracy) / dc_random_accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
